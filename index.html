
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
  <!--   <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" /> -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>Synergizing Multi-modal Agents and Large Foundation Models for Bioinformatics and Biomedicine</title>
    <!-- Favicon-->
    <link rel="icon" type="image/x-icon" href="assets/img/logo.png" />
    <!-- Font Awesome icons (free version)-->
    <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet"
        type="text/css" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="assets/css/styles.css" rel="stylesheet" />
    <link href="assets/css/mycss.css" rel="stylesheet" />
    <script>
        // 检测窗口宽度并添加或移除元素
        function toggleElementBasedOnWidth() {
            const minWidth = 1024; // 最小宽度阈值
            const elementId = 't'; // 要操作的元素的 ID
            const element = document.getElementById(elementId);
            const currentWidth = window.innerWidth; // 获取当前窗口宽度;
            if (currentWidth < minWidth) {
                // 如果窗口宽度小于最小宽度且元素存在，则移除元素
                element.style.display='none'
            } else if (currentWidth >= 1024) {
                // 如果窗口宽度大于或等于最小宽度且元素不存在，则添加元素
              
                element.style.display='flex'
            }
        }

        // 监听窗口大小变化事件
        window.addEventListener('resize', toggleElementBasedOnWidth);
        document.addEventListener('DOMContentLoaded', toggleElementBasedOnWidth);
        // 页面加载时执行一次检查
        toggleElementBasedOnWidth();
    </script>
    <style>
        hr {
            border: none;
            left: 0;
            width: 50%;
            height: 1px;
            background-color: #ffffff; /* 横线的颜色 */
            margin-top: 2px; /* 上边距 */
            margin-bottom: 2px; /* 下边距 */
        }
        .div-background {
            margin:0px;
            background: url('assets/img/Wuhan_University_Sakura_Castle.jpg') no-repeat;
            background-size: cover !important; 
            background-position: center 50% !important;
        }
        .MM_logo{
            width: 20%;
            mix-blend-mode: normal;
        }
        .aim_logo{
            z-index: 1;
            width: 12%;
            mix-blend-mode: normal;
        }
        .aiac_logo{
            width: 15%;
            mix-blend-mode: multiply;
        }
        .rose_logo{
            width: 12%;
            mix-blend-mode: multiply;
            /* multiply是混合模式，rgb相乘。normal是rgb叠加。 */
            /* mix-blend-mode: multiply; */
        }
        #submit{
            background-color: skyblue;
            vertical-align: middle; /* 垂直居中对齐 */
            border: none;
            margin-left: 10px; /* 文本和按钮之间的距离 */
            color:white;
            border-radius: 8px;
        }
        .avatar1 {
            object-fit: cover; 
            object-position: center 20%;
        }
        .avatar2 {
            object-fit: cover; 
            object-position: center 20%;
        }
        .avatar3 {
            object-fit: cover;
            object-position: center 20%;
        }
        .avatar4 {
            object-fit: cover;
            object-position: center 10%;
        }
        .avatar5 {
            object-fit: cover;
            object-position: center 20%;
        }
        .avatar6 {
            object-fit: cover; 
            object-position: center 15%;
        }
        .image-container img {
            width: 50%; 
            /* height: 100%;  */
            object-fit: contain; 
        }
        .navlogo {
            width: 10%;
        }
        #logo-nav-bar {
            width: 100%;
        }
        
       
        
        
        /* .image-container::after {
            content: ""; 
            display: block;
            width: 12rem;
            height: 1px;
            background: #fff;
            position: relative;
            bottom: -1px;
        } */
        @media (min-width: 576px){
            .col-sm-3{
                flex: 0 0 50%;
                max-width: 50%;
            }
            .col-sm-4{
                flex: 0 0 50%;
                max-width: 50%;
            }
            .col-lg-3 {
                max-width: 100%;
            }
        }
        @media (min-width: 768px){
            .col-sm-3{
                flex: 0 0 50%;
                max-width: 50%;
            }
            .col-sm-4{
                flex: 0 0 50%;
                max-width: 50%;
            }
            .col-lg-3 {
                max-width: 100%;
            }
        }
        @media (min-width: 1024px){
            .col-sm-3{
                flex: 0 0 25%;
                max-width: 25%;
            }
            .col-sm-4{
                flex: 0 0 33%;
                max-width: 33%;
            }
            .col-lg-3 {
                max-width: 100%;
            }
        }
        @media (max-width: 1024px){
            .navlogo{
                display: grid; 
                width: 100%;
                grid-template-columns: 1fr 3fr;
            }
            .buttonstyle{
                display: flex;
                align-items: flex-start;
                flex-wrap: wrap;
                flex-direction: column;
                justify-content: center;
            }
        }
        @media (max-width: 1024px) {
        #logo-nav-bar {
            display: none;
        }
    }
    .navbar {
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        background-color: white !important;
    }
    
    .nav-link {
        color: #2C3E50 !important;
        transition: all 0.3s ease;
    }
    
    .nav-link:hover {
        background-color: #006699 !important;
        color: white !important;
        border-radius: 5px;
    }
    
    .navbar-toggler {
        background-color: #006699 !important;
    }
    
    .navbar-toggler:hover {
        background-color: #004d73 !important;
    }
    
    /* 移除原来的bg-secondary类的背景色 */
    .bg-secondary {
        background-color: transparent !important;
    }
    .navbar {
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        background: linear-gradient(to right, #f8f9fa, #ffffff, #f8f9fa) !important;
        border-bottom: 1px solid rgba(0,0,0,0.05);
    }
    
    .nav-link {
        color: #2C3E50 !important;
        transition: all 0.3s ease;
        position: relative;
        font-weight: 500;
    }
    
    .nav-link:hover {
        background-color: #006699 !important;
        color: white !important;
        border-radius: 5px;
        transform: translateY(-1px);
        box-shadow: 0 2px 4px rgba(0,102,153,0.2);
    }
    
    .nav-link::after {
        content: '';
        position: absolute;
        width: 0;
        height: 2px;
        bottom: 0;
        left: 50%;
        background-color: #006699;
        transition: all 0.3s ease;
    }
    
    .nav-link:hover::after {
        width: 100%;
        left: 0;
    }
    
    .navbar-toggler {
        background-color: #006699 !important;
        border: none;
        padding: 0.5rem 1rem;
        transition: all 0.3s ease;
    }
    
    .navbar-toggler:hover {
        background-color: #004d73 !important;
        transform: translateY(-1px);
        box-shadow: 0 2px 4px rgba(0,0,0,0.2);
    }
    
    /* 移除原来的bg-secondary类的背景色 */
    .bg-secondary {
        background-color: transparent !important;
    }
    
    /* 添加一些微妙的动画效果 */
    .navbar-nav {
        transition: all 0.3s ease;
    }
    
    .navbar-nav:hover .nav-link:not(:hover) {
        opacity: 0.8;
    }
    
    /* 响应式调整 */
    @media (max-width: 992px) {
        .navbar {
            background: #ffffff !important;
        }
        
        .nav-link {
            padding: 0.5rem 1rem !important;
            margin: 0.2rem 0;
        }
        
        .nav-link:hover {
            transform: none;
        }
    }
    .nav-link {
        color: #2C3E50 !important;
        transition: all 0.3s ease;
        position: relative;
        font-weight: 500;
        font-size: 1.1rem !important;  /* 增加字体大小 */
        letter-spacing: 0.5px;  /* 增加字母间距，提高可读性 */
    }

    

    </style>
</head>


<body id="page-top">
    <!-- Navigation -->
<!-- Navigation -->
<nav class="navbar navbar-expand-lg text-uppercase fixed-top" id="mainNav">
    <div class="navlogo">
        <div class="buttonstyle">
            <button
            style="background-color: #004d73 !important;"   
            class="navbar-toggler navbar-toggler-right text-uppercase font-weight-bold text-white rounded"
                type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive"
                aria-expanded="false" aria-label="Toggle navigation">
                Menu
                <i class="fas fa-bars"></i>
            </button>
        </div>
        <img id="logo-nav-bar" src="assets/img/logo.png" alt="">
    </div>
    <div class="container">
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item mx-0 mx-lg-1">
                    <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#topics" id="CallforPapers">Call for Papers</a>
                </li>
                <li class="nav-item mx-0 mx-lg-1">
                    <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#schedule">DATES</a>
                </li>
                <li class="nav-item mx-0 mx-lg-1">
                    <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#submission" id="Submission">Submission</a>
                </li>
                <li class="nav-item mx-0 mx-lg-1">
                    <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#speakers">Keynotes</a>
                </li>
                <li class="nav-item mx-0 mx-lg-1">
                    <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#ProgramCommittee">Program Committee</a>
                </li>
                <li class="nav-item mx-0 mx-lg-1">
                    <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#GeneralChairs">Organizers</a>
                </li>
            </ul>
        </div>
    </div>
</nav>

    <!-- Masthead -->
    <header style="background-color: rgb(255, 255, 255) !important;width: 100vw;" class="masthead bg-primary text-white text-center div-background">
        <!-- <div class="container d-flex align-items-center flex-column"> -->
            <!-- MM的背景图有些看不清楚，加了黑色底色。但是图片还是有些看不清楚。删除黑色底色用上面的注释的div class -->
        <div style="background-color: rgba(0,0,0,0.5); padding: 2rem;" class="container d-flex align-items-center flex-column">

            <!-- Masthead Heading -->
            <h1 class="masthead-heading mb-0">Synergizing Multi-modal Agents and Large Foundation Models for Bioinformatics and Biomedicine

            </h1>

            <!-- Masthead Subheading -->
            <p class="masthead-subheading font-weight-light mb-0">
                Co-located with The IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2025
                <br/>
                15 December - 18 December 2025, Wuhan, China
                <br />
            </p>
            <!-- <div style="padding-bottom: 5rem;"> -->
                <!-- <img src="assets/img/mm2025.png" class="MM_logo" alt="MM_logo"> -->
                <!-- <br> -->
<!--                 <img src="assets/img/logo/aim_logo.png" class="aim_logo" alt="aim_logo">
                <img src="assets/img/logo/aiac_logo.jpg" class="aiac_logo" alt="aiac_logo">
                <img src="assets/img/logo/rose_logo.jpg" class="rose_logo" alt="rose_logo"> -->
            <!-- </div> -->
        </div>
    </header>
    <section class="page-section portfolio bg-light" id="">
        <div class="container">
            <!-- About Section Heading -->
            <h2 class="page-section-heading text-center text-uppercase text-secondary mb-5">overview</h2>

            <!--<h3>Topics</h3>-->
            <p class="lead text-justify">
                The convergence of multi-modal agents and large foundation models is opening up transformative possibilities in bioinformatics and biomedicine. With the explosion of biological and biomedical data—from genomic sequences and proteomics to biomedical imaging and electronic health records—the need for intelligent systems that can effectively integrate and interpret this information has never been more critical. Multi-modal agents are designed to seamlessly process data across diverse modalities, while large foundation models, pre-trained on massive datasets, offer powerful generalization capabilities and adaptability across tasks.
                <br />
                <br />
                This workshop aims to explore how the synergy between these two approaches can address long-standing challenges in the field, such as data heterogeneity, limited annotations, and model interpretability. By combining multi-modal agents with large foundation models, we can enable more robust disease gene prediction, biomarker discovery, drug response modeling, and other key tasks in computational biology and biomedicine.
                <br />
                <br />
                The goal of this workshop is to bring together researchers and practitioners from machine learning, bioinformatics, and biomedical sciences to share insights, foster collaborations, and chart new directions. We are particularly interested in approaches that demonstrate:
                <ul class="lead">
                    <li><b>Integrative Data Analysis:</b> Using multi-modal strategies to connect and analyze omics data, imaging, and clinical records.</li>
                    <br>
                    <li><b>Knowledge Transfer:</b> Leveraging foundation models to overcome data scarcity in biomedical domains.</li>
                    <br>
                    <li><b>Scalable and Trustworthy Systems:</b>Building robust, interpretable tools for real-world biomedicine.</li>
                    <br>
                    <li><b>Novel Applications:</b> Exploring innovative use cases in personalized medicine, drug discovery, and beyond.</li>
                
                </ul>
                <br />
                
        </div>
    </section>
    <section class="page-section portfolio bg-transparent" id="topics">
        <div class="container">
            <!-- About Section Heading -->
            <h2 class="page-section-heading text-center text-uppercase text-secondary mb-5">Topics and Areas</h2>

            <!--<h3>Topics</h3>-->
            <p class="lead text-justify">
                This workshop invites contributions that explore the integration of multi-modal agents and large foundation models to advance research and applications in <b>bioinformatics and biomedicine</b>. Topics of interest include, but are not limited to: 
                <br />
                <ul class="lead">
                    <li><b>Integration Techniques for Multi-modal Biological and Biomedical Data</b></li>
                    <ul style="margin-top: 10px;">
                        <li>Novel methods for fusing omics data, biomedical images, clinical records, and biosignals using large foundation models.</li>
                        <li>Techniques for aligning, synchronizing, and harmonizing heterogeneous biological data sources across modalities.</li>
                    </ul>
                    <li><b>Adaptation of Foundation Models to Bioinformatics and Biomedical Domains</b></li>
                    <ul style="margin-top: 10px;">
                        <li>Transfer learning strategies for applying pre-trained models to tasks like genome analysis, proteomics, transcriptomics, and molecular phenotyping.</li>
                        <li>Domain-specific fine-tuning of foundation models for multi-modal biomedical applications.</li>
                    </ul>
                    <li><b>Development of Intelligent Multi-modal Agents for Biomedicine</b></li>
                    <ul style="margin-top: 10px;">
                        <li>Design of AI agents that leverage foundation models to support decision-making in areas such as drug discovery, disease classification, and biomarker identification.</li>
                        <li>Applications of multi-modal agents in personalized medicine, precision health, and biomedical research.</li>
                    </ul>
                    
                    <li><b>Cross-modal and Multi-scale Representation Learning</b></li>
                    <ul style="margin-top: 10px;">
                        <li>Learning unified and interpretable representations across modalities (e.g., integrating genetic data with imaging or EHRs).</li>
                        <li>Techniques for linking molecular-level data with phenotype or population-level information through foundation models.</li>
                    </ul>
                    
                    <li><b>Biomedical Case Studies and Applications</b></li>
                    <ul style="margin-top: 10px;">
                        <li>Real-world case studies demonstrating the utility of combining multi-modal agents with large foundation models.</li>
                        <li>Evaluations of performance, interpretability, and impact in clinical and research settings.</li>
                    </ul>
                    
                    <li><b>Scalability, Efficiency, and Deployment</b></li>
                    <ul style="margin-top: 10px;">
                        <li>Computational strategies to scale foundation models for use in bioinformatics workflows and clinical pipelines.</li>
                        <li>Resource-efficient model deployment, including cloud-based and edge AI approaches for large-scale biomedical data.</li>
                    </ul>
                    
                    <li><b>Explainability and Trust in Biomedical AI</b></li>
                    <ul style="margin-top: 10px;">
                        <li>Frameworks to enhance transparency, reliability, and trustworthiness in multi-modal biomedical AI systems.</li>
                        <li>Visualization and interaction tools to support domain experts in interpreting model predictions.</li>
                    </ul>
                    
                    <li><b>Standardization, Benchmarks, and Evaluation Frameworks</b></li>
                    <ul style="margin-top: 10px;">
                        <li>Creation of benchmark datasets for evaluating multi-modal foundation model approaches in bioinformatics.</li>
                        <li>Comparative studies of model performance, robustness, and generalizability across tasks and data types.</li>
                    </ul>
                    
                    
                    
                </ul>
        </div>
    </section>

    <!-- <section class="page-section portfolio bg-light" id="relevance">


        <div class="container">

            <h2 class="page-section-heading text-center text-uppercase text-secondary mb-5">Relevance to ACM Multimedia 2023</h2>

            <p class="lead text-justify">

                The proposed Workshop will focus on the different aspects of industry multimedia computing and measurements with advanced artificial intelligence models, i.e., deep learning, natural language processing, semantic analysis, and pattern recognition. It provides an opportunity for input from multimedia computing-oriented researchers and those from the industry. To the best of our knowledge, this topic has not yet been the central focus of any of the ACM MM workshops. The particular scope of the suggested workshop falls well within the scope of the ACM MM 2023 and would benefit its reader audience. The reputation and popularity of the ACMM MM conference will definitely contribute to the synergy between this and adjacent or complementary fields.

                
            </p>
        </div>
    </section> -->

    <!-- <section class="page-section bg-light" id="accepted-papers">


        <div class="container">
            <h2 class="page-section-heading text-center text-uppercase text-secondary mb-5">Accepted Papers</h2>

            <h3 class="text-center text-uppercase my-2">Full Papers</h3>
            <ul>
                <li><b>Graph2Feat: Inductive Link Prediction via Knowledge Distillation.</b> Ahmed E. Samy, Zekarias T. Kefato and Sarunas Girdzijauskas; (Representation) <a href="" target="_blank" style="color: lightgray;">read paper <i class="fas fa-file-pdf"></i> (available soon)</a></li>
                <li><b>Assessing Scientific Contributions in Data Sharing Spaces.</b> Kacy Adams, Fernando Spadea, Conor Flynn and Oshani Seneviratne; (Assessment) <a href="https://arxiv.org/abs/2303.10476" target="_blank">read paper <i class="fas fa-file-pdf"></i></a></li>
                <li><b>A New Annotation Method and Dataset for Layout Analysis of Long Documents.</b> Aman Ahuja, Kevin Dinh, Brian Dinh, William A. Ingram and Edward Fox; (Representation) <a href="" target="_blank" style="color: lightgray;">read paper <i class="fas fa-file-pdf"></i> (available soon)</a></li>
                <li><b>Towards InnoGraph: A Knowledge Graph for AI Innovation.</b> M.Besher Massri, Blerina Spahiu, Marko Grobelnik, Vladimir Alexiev, Matteo Palmonari and Dumitru Roman; (Representation) <a href="https://zenodo.org/record/7750707#.ZBd9vHbMISE" target="_blank">read paper <i class="fas fa-file-pdf"></i></a></li></ul>

            <h3 class="text-center text-uppercase my-2">Short Papers</h3>
            <ul>
                <li><b>Graph Embedding for Mapping Interdisciplinary Research Networks.</b> Eoghan Cunningham and Derek Greene; (Representation) <a href="https://arxiv.org/abs/2302.01826" target="_blank">read paper <i class="fas fa-file-pdf"></i></a></li>
                <li><b>Cross-Team Collaboration and Diversity in the Bridge2AI Project.</b> Huimin Xu, Chitrank Gupta, Zhandos Sembay, Swathi Thaker, Pamela Payne-Foster, Jake Chen and Ying Ding; (Assessment) <a href="" target="_blank" style="color: lightgray;">read paper <i class="fas fa-file-pdf"></i> (available soon)</a></li>
                <li><b>NASA Science Mission Directorate Knowledge Graph Discovery.</b> Roelien C. Timmer, Megan Mark, Fech Scen Khoo, Marcella Scoczynski Ribeiro Martins, Anamaria Berea, Greg Renard, Kaylin Bugbee and Emily Foshee; (Representation) <a href="https://arxiv.org/abs/2303.10871" target="_blank">read paper <i class="fas fa-file-pdf"></i></a></li>
                <li><b>Scientific Data Extraction from Oceanographic Papers.</b> Bartal Eyðfinsson Veyhe, Tomer Sagi and Katja Hose; (Discoverability) <a href="" target="_blank" style="color: lightgray;">read paper <i class="fas fa-file-pdf"></i> (available soon)</a></li>
                <li><b>hp-frac: An index to determine Awarded Researchers.</b> Aashay Singhal and Kamalakar Karlapalem; (Assessment) <a href="" target="_blank" style="color: lightgray;">read paper <i class="fas fa-file-pdf"></i> (available soon)</a></li>
                <li><b>Application of an ontology for model cards to generate computable artifacts for linking machine learning information from biomedical research.</b> Muhammad Amith, Licong Cui, Kirk Roberts and Cui Tao; (Discoverability) <a href="https://arxiv.org/abs/2303.11991" target="_blank">read paper <i class="fas fa-file-pdf"></i></a></li>
            </ul>
        </div>
    </section> -->


    <!-- <section class="page-section portfolio bg-light" id="significance">


        <div class="container">

            <h2 class="page-section-heading text-center text-uppercase text-secondary mb-5">Significance</h2>

            <p class="lead text-justify">

                Considering the significance of multimedia computing for smart manufacturing, this workshop will be a timely platform to bring together researchers to further explore innovative multimedia computing methods for intelligent industry applications in the era of Industry 5.0. The significance of this workshop is to bring the latest theoretical and practical advancements in artificial intelligence, the Internet of things, 5G, image processing, and big data to the field of multimedia. With the support of advanced multimedia computing technologies, the significant insights and knowledge hidden behind industry sensors can be capitalized for process optimization, anomaly detection, energy management, and so on. We must try our best to mine and extract knowledge out of industry multimedia big data through a series of intelligent technologies and methods, including sensor data planning, acquisition, preprocessing, storage, analytical mining, visualization, and intelligent control. It is expected that the workshop will provide many new ideas for industry multimedia computing processing which are very important for the development of the future world. The sooner we start this workshop, the better for the construction industry, local communities, and society in general.
                
            </p>
        </div>
    </section> -->
    <section class="page-section bg-transparent mb-0" id="schedule">

        <div class="container">

            <h2 class="page-section-heading text-center text-uppercase  mb-5">Important Date:</h2>
            <br>
            <ul class="lead text-justify">
                <li>Workshop paper submission deadline: <b style="color: red;">15 October 2025</b></li>
                <br>
                <li>Workshop paper notification: <b style="color: red;">10 November 2025</b></li>
                <br>
                <li>Workshop paper camera-ready: <b>23 November 2025</b></li>
                <br>
                <li>Workshop dates: <b>15-18 December 2025</b></li>
                <br>                
            </ul>

        </div>
    </section>

    <section class="page-section portfolio bg-light" id="submission">
        <h2 class="page-section-heading text-center text-uppercase text-secondary mb-5">Submission</h2>
        <div class="container">
            <ul class="lead">
                <li><b>Submit a New Paper</b></li>
                <p class="mt-3">
                    Papers should be formatted according to the IEEE Computer Society Proceedings Manuscript Formatting Guidelines. 
                    The template can be found via: 
                    <a href="https://www.ieee.org/conferences/publishing/templates.html" target="_blank">
                        <button id="submit">Template</button>
                    </a>
                </p>
    
                <li><b>Important Notes:</b></li>
                <ul style="margin-top: 10px;">
                    <li>Papers should be formatted to 8 pages IEEE Computer Society Proceedings Manuscript Formatting Guidelines.</li>
                    <li>You are strongly encouraged to print and double check your PDF file before its submission, especially if your paper contains Asian/European language symbols (such as Chinese/Korean characters or English letters with European fonts).</li>
                </ul>
                
                <li><b>Transfer Policy:</b></li>
                <p class="mt-3">
                    If your paper was submitted but not accepted in the main conference, you cannot directly submit it to a workshop but it must be transferred into the workshop. You can change this option (workshop) at the conference paper submission site or (after the deadline) request the organizer of the workshop to which you want your paper to be transferred.
                </p>
    
                <li><b>Submission Links:</b></li>
                <ul style="margin-top: 10px;">
                    <li>Submit a new paper: 
                        <a href="https://wi-lab.com/cyberchair/2025/bibm25/scripts/submit.php?subarea=S22&undisplay_detail=1&wh=/cyberchair/2025/bibm25/scripts/ws_submit.php">
                            <button id="submit">Submit a New Paper</button>
                        </a>
                    </li>
                    </li>
                </ul>
            </ul>
        </div>
    </section>


    <!-- <section class="page-section bg-light mb-0" id="SteeringCommittee">

        <div class="container">

            <h2 class="page-section-heading text-center text-uppercase mb-5">Steering Committee</h2>

            <br>
            <ul class="lead text-justify">
                <li><b>Xuequan Lu</b>, UWA, Australia</li><br>
                <li><b>Imran Razzak</b>, MBZUAI, UAE</li><br>
            </ul>
        </div>

        </div>
    </section> -->
    <section class="page-section bg-transparent" id="speakers">
        <div class="container">
            <h2 class="page-section-heading text-center text-uppercase text-secondary mb-5">Keynote Speakers</h2>
            
            <div class="row justify-content-center">
                <div class="col-lg-8 text-center">
                    <div class="keynote-placeholder">
                        <i class="fas fa-user-circle fa-5x mb-3" style="color: #666;"></i>
                        <h3 class="text-secondary mb-4">Keynote Speakers</h3>
                        <p class="lead">To be Confirmed...</p>
                    </div>
                </div>
            </div>
    
            <!-- 当确认了演讲者后，可以使用下面的模板 -->
            <!--
            <div class="row">
                <div class="col-md-6 mb-5">
                    <div class="card h-100">
                        <div class="card-body text-center">
                            <img class="rounded-circle mb-3" src="path_to_speaker_image.jpg" alt="Speaker Name" 
                                 style="width: 200px; height: 200px; object-fit: cover;">
                            <h4 class="card-title">Speaker Name</h4>
                            <p class="text-secondary">Position</p>
                            <p class="text-secondary">Institution</p>
                            <p class="lead">Brief biography and research interests...</p>
                            <p class="font-weight-bold mt-3">Keynote Title: TBA</p>
                        </div>
                    </div>
                </div>
            </div>
            -->
        </div>
    </section>

    <section class="page-section bg-transparent mb-0" id="GeneralChairs">
        <div class="container">
            <h2 class="page-section-heading text-center text-uppercase mb-5">Workshop Organizers</h2>
            <br>
            <div class="row justify-content-center"> <!-- 添加justify-content-center使内容居中 -->
            <!-- Yanda Meng -->
            <div class="col-12 mb-5">
                <div class="d-flex align-items-start"> <!-- 改为align-items-start确保顶部对齐 -->
                    <img class="rounded-circle" src="assets/img/Mengyanda.jpg" alt="" 
                        style="width: 200px; height: 200px; object-fit: cover; margin-right: 30px;"> <!-- 增加图片尺寸和右边距 -->
                    <div>
                        <h4><a href="https://yanda-meng.github.io/">Yanda Meng</a></h4>
                        <p class="text-secondary">University of Exeter, UK</p>
                        <p class="lead" style="text-align: justify;"><b>Dr. Yanda Meng</b> is an assistant professor (UK Lecturer) at the University of Exeter, Computer Science Department. His research is mainly at the interface of artificial intelligence and healthcare, specialised in the research and development of artificial intelligence, biomedical image processing and analysis techniques. He has published more than 40 papers in peer-reviewed journals and conferences such as IEEE Transactions on Medical Imaging, Medical Image Analysis, Diabetologia, Cardiovascular Diabetology, CVPR, ICCV, ECCV, AAAI, and MICCAI, etc. He has leadership roles as project PI delivering successful projects working effectively with different stakeholders (academics, clinicians, public, and industry). His collaboration with clinicians has made significant impacts on patient care. His research has been or is being supported by UKRI, UK Royal Society, Exeter Innovation, NHS Foundation Trust, and Welcome Trust. Yanda has also served as the Topic Editor and Guest Editor for many journals, such as IEEE JBHI, Frontiers in Medicine, Mathematics; the Area Chair for MICCAI 2025 and IEEE ICARM 2025; the Program Committee Board member for ISBI 2026.</p>
                        </div>
                    </div>
                </div>
            <!-- Wei Zhou -->
            <div class="col-12 mb-5">
                <div class="d-flex align-items-start">
                    <img class="rounded-circle" src="assets/img/weizhou23.jpg" alt="" 
                        style="width: 200px; height: 200px; object-fit: cover; margin-right: 30px;">
                    <div>
                        <h4><a href="https://weizhou-geek.github.io/">Wei Zhou</a></h4>
                        <p class="text-secondary">Cardiff University, UK</p>
                            <p class="lead" style="text-align: justify;"><b>Dr. Wei Zhou</b> is an Assistant Professor (UK Lecturer) at Cardiff University. Wei’s research interests
                                mainly focus on perceptual image processing, multimodality, and visual computing for healthcare. Dr
                                Zhou has published over 70 papers in recent years, including publications in top-tier venues, e.g., IEEE TIP, IEEE TMM, IEEE TCSVT, IEEE TMI, CVPR, ACM MM, MICCAI, etc. Wei serves as General Chair for the 1st Cardiff Image & Vision Computing Workshop and Chair for the Elections Committee of IEEE UK & Ireland SPS Chapter. Wei is now an Associate Editor of IEEE Transactions on Neural Networks and Learning Systems (TNNLS), Pattern Recognition, Neurocomputing, Springer Signal, Image and Video Processing, and Human-centric Computing and Information Sciences. Wei has also served as the Topic Editor and Guest Editor for many journals, such as Elsevier Displays; the Area Chair for ACM MM 2024, ICME 2025, and IJCNN 2025; the Lead Special Session Chair for IEEE ICME 2025, IEEE QoMEX 2025, IEEE MMSP 2023, and the Special Session Co-Chair for IEEE ICIP 2025 and 2024.
                                </p>
                        </div>
                    </div>
                </div>

    
            <!-- Meng Wang -->
            <div class="col-12 mb-5">
                <div class="d-flex align-items-start">
                    <img class="rounded-circle" src="assets/img/wangm.jpg" alt="" 
                        style="width: 200px; height: 200px; object-fit: cover; margin-right: 30px;">
                        <div style="margin-left: 40px;"> <!-- 添加左边距 -->
                            <h4><a href="https://wangm92nus.github.io/">Meng Wang</a></h4>
                        <p class="text-secondary">National University of Singapore, Singapore</p>
                            <p class="lead" style="text-align: justify;"><b>Dr Meng Wang</b> is a Research Fellow at the Centre for Innovation and Precision Eye Health, National University of Singapore. His research focuses on medical artificial intelligence and multimodal medical image analysis, specifically emphasizing medical image analysis, large foundation models for medical imaging, and trustworthy AI. Dr. Meng Wang has published over 50 papers, including in top international journals like Nature Communications, npj Digital Medicine, Cell Reports Medicine, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), and IEEE Transactions on Medical Imaging (TMI), as well as at leading international conferences such as CVPR and MICCAI. He has also contributed to the authorship of the specialized book "Federated Learning for Medical Imaging.</p>
                        </div>
                    </div>
                </div>
    
            <!-- Qinkai Yu -->
            <div class="col-12 mb-5">
                <div class="d-flex align-items-start">
                    <img class="rounded-circle" src="assets/img/qinkai.jpg" alt="" 
                        style="width: 200px; height: 200px; object-fit: cover; margin-right: 30px;">
                        <div style="margin-left: 15px;"> <!-- 添加左边距 -->
                            <h4><a href="https://scholar.google.com/citations?user=91kKHIcAAAAJ&hl=zh-CN&oi=ao">Qinkai Yu</a></h4>
                        <p class="text-secondary">University of Exeter, UK</p>
                            <p class="lead" style="text-align: justify;"><b>Mr Qinkai Yu</b> is a PhD student in the Department of Computer Science at the University of Exeter, under the supervision of Dr. Yanda Meng. His research lies at the intersection of medical image analysis and the application of large language models and multimodal foundation models in healthcare. He has published multiple papers as the first author or co-first author in top-tier peer-reviewed conferences such as ACL, COLING, and MICCAI. In 2025, two of his first-author papers have been accepted early by MICCAI.</p>
                        </div>
                    </div>
                </div>
    
            </div>
        </div>
    </section>
    <section class="page-section bg-light mb-0" id="ProgramCommittee">
        <div class="container">
            <h2 class="page-section-heading text-center text-uppercase mb-5">Program Committee</h2>
            <br>
            <ul class="lead text-justify">
                <li>
                    <b>Yitian Zhao</b><br>
                    Professor<br>
                    Ningbo Institute of Materials Technology and Engineering<br>
                    Chinese Academy of Sciences, Ningbo, China
                </li><br>
    
                <li>
                    <b>Cheng Chen</b><br>
                    Assistant Professor<br>
                    Department of Electrical and Electronic Engineering<br>
                    University of Hong Kong, Hong Kong, China
                </li><br>
    
                <li>
                    <b>Bo Huang</b><br>
                    Associate Professor<br>
                    College of Optoelectronic Engineering<br>
                    Chongqing University, Chongqing, China
                </li><br>
    
                <li>
                    <b>Huazhu Fu</b><br>
                    Principle Scientist<br>
                    Institute of High Performance Computing<br>
                    Agency for Science, Technology and Research (A*STAR), Singapore, Singapore
                </li><br>
    
                <li>
                    <b>Guanghui Yue</b><br>
                    Associate Professor<br>
                    School of Biomedical Engineering<br>
                    Shenzhen University, Shenzhen, China
                </li><br>
    
                <li>
                    <b>Lichi Zhang</b><br>
                    Associate Professor<br>
                    School of Biomedical Engineering<br>
                    Shanghai Jiao Tong University, Shanghai, China
                </li><br>
    
                <li>
                    <b>Guang Yang</b><br>
                    Associate Professor<br>
                    School of Bioengineering<br>
                    Imperial College London, London, UK
                </li><br>
    
                <li>
                    <b>Liming Chen</b><br>
                    Professor<br>
                    Computer Science and Technology Department<br>
                    Dalian University of Technology, Dalian, China
                </li><br>
    
                <li>
                    <b>Jungong Han</b><br>
                    Chair Professor<br>
                    Institute of Brain and Cognitive Sciences<br>
                    Tsinghua University, Beijing, China
                </li><br>
    
                <li>
                    <b>Yalin Zheng</b><br>
                    Professor<br>
                    Eye and Vision Science Department<br>
                    University of Liverpool, Liverpool, UK
                </li><br>
            </ul>
        </div>
    </section>
    <!-- Footer -->
    <footer class="footer text-center">
        <div class="container">
            <div class="row">

                <!-- Footer Location -->
                <div class="col-lg-3 mb-5 mb-lg-0">
                </div>

                <!-- Footer Social Icons -->
                <div class="col-lg-6 mb-5 mb-lg-0">
                    <h4 class="text-uppercase mb-4">Follow Synergizing Multi-modal Agents and Large Foundation Models for Bioinformatics and Biomedicine (updating)</h4>
                    <!-- <a class="btn btn-outline-light btn-social mx-1" href="#">
                           <i class="fab fa-fw fa-facebook-f"></i>
                         </a> -->
                    <!-- <a class="btn btn-outline-light btn-social mx-1" href="https://twitter.com/scik_workshop"
                        target="_blank">
                        <i class="fab fa-fw fa-twitter"></i>
                    </a>
                    <a class="btn btn-outline-light btn-social mx-1" href="https://www.linkedin.com/groups/9300118/">
                          <i class="fab fa-fw fa-linkedin-in"></i>
                    </a> -->
                    <!-- 
                        <a class="btn btn-outline-light btn-social mx-1" href="#">
                          <i class="fab fa-fw fa-dribbble"></i>
                        </a> -->
                </div>

                <!-- Footer About Text -->
                <div class="col-lg-3">
                </div>

            </div>
        </div>
    </footer>

    <!-- Copyright Section -->
    <section class="copyright py-4 text-center text-white">
        <div class="container">
            <small>Copyright &copy; Synergizing Multi-modal Agents and Large Foundation Models for Bioinformatics and Biomedicine</small>
        </div>
    </section>

    <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
    <div class="scroll-to-top d-lg-none position-fixed ">
        <a class="js-scroll-trigger d-block text-center text-white rounded" href="#page-top">
            <i class="fa fa-chevron-up"></i>
        </a>
    </div>

    <!-- Bootstrap core JS-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Third party plugin JS-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
    <!-- Contact form JS-->
    <script src="assets/mail/jqBootstrapValidation.js"></script>
    <script src="assets/mail/contact_me.js"></script>
    <!-- Core theme JS-->
    <script src="assets/js/scripts.js"></script>
    <script src="assets/js/moment.js"></script>
    <script src="assets/js/moment-timezone-with-data.js"></script>
    <script src="assets/js/myjs.js"></script>
</body>

</html>
